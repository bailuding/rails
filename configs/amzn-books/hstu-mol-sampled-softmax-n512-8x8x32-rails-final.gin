# Efficient Retrieval with Learned Similarities (RAILS).
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Run this as:
# mkdir -p logs/amzn-books-l50/
# CUDA_VISIBLE_DEVICES=0,1 python3 train.py --gin_config_file=configs/amzn-books/hstu-mol-sampled-softmax-n512-8x8x32-rails-final.gin --master_port=12345 2>&1 | tee logs/amzn-books-l50/hstu-mol-sampled-softmax-n512-8x8x32-rails-final.log
#                                 | full/hr@1      full/hr@10     full/hr@50     full/hr@200    full/ndcg@10   full/ndcg@50   full/ndcg@200  full/mrr      
#   HSTU (b=16, h=4, d=64, n=512) | 0.0102         0.0462         0.1042         0.1845         0.0256         0.0381         0.0502         0.0232        
#               HSTU+MoL - final  | 0.0150 (47.1%) 0.0613 (33.0%) 0.1292 (24.0%) 0.2167 (17.5%) 0.0350 (37.3%) 0.0498 (30.7%) 0.0629 (25.5%) 0.0315 (36.4%)
#
# offline full eval:
# eval @ epoch 115 (10858 iters, 694912 evaluated) in 3419.44s: NDCG@1 0.0150, NDCG@5 0.0289, NDCG@10 0.0350, NDCG@50 0.0498, NDCG@100 0.0564, NDCG@200 0.0629, HR@1 0.0150, HR@5 0.0422, HR@10 0.0613, HR@50 0.1293, HR@100 0.1699, HR@200 0.2168, MRR 0.0316

train_fn.dataset_name = "amzn-books"
train_fn.max_sequence_length = 50
train_fn.local_batch_size = 64
train_fn.eval_batch_size = 64
train_fn.eval_user_max_batch_size = 64  # otherwise need to fix uid logic

train_fn.main_module = "HSTU"
train_fn.main_module_bf16 = True
train_fn.item_embedding_dim = 64
train_fn.dropout_rate = 0.5
train_fn.user_embedding_norm = "layer_norm"
train_fn.item_embedding_dim = 64

hstu_encoder.num_blocks = 16
hstu_encoder.num_heads = 8
hstu_encoder.dqk = 8
hstu_encoder.dv = 8
hstu_encoder.linear_dropout_rate = 0.5

train_fn.eval_interval = 1000
train_fn.num_epochs = 201
train_fn.learning_rate = 1e-3
train_fn.weight_decay = 0
train_fn.num_warmup_steps = 0

# train_fn.save_ckpt_every_n = 5

train_fn.interaction_module_type = "MoL"
train_fn.top_k_method = "MoLBruteForceTopK"

create_mol_interaction_module.query_dot_product_groups = 8
create_mol_interaction_module.item_dot_product_groups = 8
create_mol_interaction_module.dot_product_dimension = 32
create_mol_interaction_module.dot_product_l2_norm = True

# MoL query-side configuration
create_mol_interaction_module.query_use_identity_fn = False
create_mol_interaction_module.query_hidden_dim = 512
create_mol_interaction_module.query_nonlinearity = "geglu"
create_mol_interaction_module.query_dropout_rate = 0.0

# MoL item-side configuration
create_mol_interaction_module.item_use_identity_fn = False
create_mol_interaction_module.item_dropout_rate = 0.1
create_mol_interaction_module.item_hidden_dim = -1
create_mol_interaction_module.item_nonlinearity = "geglu"

create_mol_interaction_module.gating_query_hidden_dim = 128
create_mol_interaction_module.gating_item_hidden_dim = 128
create_mol_interaction_module.gating_item_dropout_rate = 0.0
create_mol_interaction_module.gating_qi_hidden_dim = 128
create_mol_interaction_module.gating_qi_dropout_rate = 0.0
create_mol_interaction_module.gating_combination_type = "glu_silu"
create_mol_interaction_module.softmax_dropout_rate = 0.2
create_mol_interaction_module.temperature = 0.05

train_fn.loss_module = "SampledSoftmaxLoss"
train_fn.num_negatives = 512
train_fn.temperature = 1.0

train_fn.sampling_strategy = "local"
train_fn.item_l2_norm = False
train_fn.l2_norm_eps = 1e-6

train_fn.enable_tf32 = True
train_fn.full_eval_every_n = 5
train_fn.partial_eval_num_iters = 32

create_data_loader.prefetch_factor = 1024
create_data_loader.num_workers = 8
